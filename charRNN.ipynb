{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import en_core_web_sm\n",
    "from multiprocessing import Pool#multi-threads\n",
    "pool = Pool(10)\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader_general import data_reader, data_generator\n",
    "class config:\n",
    "    is_stanford_nlp = False\n",
    "    embed_path = 'data/tweets/vocab/lower_local_emb.pkl'\n",
    "    word_num = 19174\n",
    "    embed_dim = 300\n",
    "    char_num = 150\n",
    "    char_dim = 128\n",
    "    l_hidden_size =128\n",
    "    mask_dim = 30\n",
    "    dic_path = 'data/tweets/vocab/lower_dict.pkl'\n",
    "    pretrained_embed_path = '../data/glove.840B.300d.txt'\n",
    "    train_path = 'data/tweets/train_lower.pkl'\n",
    "    valid_path = 'data/tweets/valid_lower.pkl'\n",
    "    test_path = 'data/tweets/test_lower.pkl'\n",
    "    data_path = 'data/tweets/'\n",
    "    elmo_config_file = None\n",
    "    elmo_weight_file= None\n",
    "    use_label_dict = False\n",
    "    batch_size = 8\n",
    "    dropout = 0.2\n",
    "    if_gpu = False\n",
    "dr = data_reader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dr.load_data(config.train_path)\n",
    "valid_data = dr.load_data(config.valid_path)\n",
    "test_data = dr.load_data(config.test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 5206\n",
      "Validating Samples: 1042\n",
      "Testing Samples: 692\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Samples: {}\".format(len(train_data)))\n",
    "print(\"Validating Samples: {}\".format(len(valid_data)))\n",
    "print(\"Testing Samples: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_train = data_generator(config,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/ForkPoolWorker-11] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-12] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-13] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-14] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-15] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-16] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-17] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-18] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-19] child process calling self.run()\n",
      "[INFO/ForkPoolWorker-20] child process calling self.run()\n"
     ]
    }
   ],
   "source": [
    "sent_ids, mask_vecs, label_list, sent_lens, batch_char_ids_tensor, batch_char_lens_tensor, tokens = next(dg_train.get_char_ids_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hier_layer import SimpleCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = SimpleCat(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vec, char_output = layer(sent_ids, mask_vecs, sent_lens, batch_char_ids_tensor, batch_char_lens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 158])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 330])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_vec.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 33, 300])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  1,  7,  1,  1,  2,  3,  4,  2,  6,  3, 10,  3,  3,  2,  3,  6,  3,\n",
       "         3,  2,  5,  5,  1,  4,  7,  2,  3,  1,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_char_lens_tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_lens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [item[-3] for item in train_data]\n",
    "text += [item[-3] for item in valid_data]\n",
    "text += [item[-3] for item in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "long_text = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_freq = Counter(long_text).most_common(138)\n",
    "len(char_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars, _ = zip(*char_freq)\n",
    "#chars = chars[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "char_id = {char:i for i, char in enumerate(chars)}\n",
    "id_char = {i:char for i, char in enumerate(chars)}\n",
    "with open('data/tweets/vocab/char_dict', 'wb') as f:\n",
    "    pickle.dump([char_id, id_char, chars], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_char_lens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
