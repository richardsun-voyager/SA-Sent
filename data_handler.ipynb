{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "import codecs\n",
    "from config import config\n",
    "from bs4 import BeautifulSoup\n",
    "import pdb\n",
    "import torch\n",
    "from nltk.tokenize import word_tokenize\n",
    "#import tokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "##Added by Richard Sun\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from data_reader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"data/2014/Restaurants_Train_v2.xml\"\n",
    "TEST_DATA_PATH = \"data/2014/Restaurants_Test_Gold.xml\"\n",
    "TRAIN_DATA_PATH = \"data/Indonesian/indo_tweets.csv\"\n",
    "\n",
    "# TRAIN_DATA_PATH = \"./data/2014/Laptop_Train_v2.xml\"\n",
    "# TEST_DATA_PATH = \"./data/2014/Laptops_Test_Gold.xml\"\n",
    "\n",
    "GLOVE_FILE = \"../data/word_embeddings/indo_vectors.txt\"\n",
    "OUT_FILE = config.embed_path\n",
    "DATA_FILE = config.data_path\n",
    "DIC_FILE = config.dic_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install xlrd\n",
    "import pandas as pd\n",
    "#help(pd.read_excel)\n",
    "data = pd.read_csv(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        7132\n",
       "unique          3\n",
       "top       Neutral\n",
       "freq         3091\n",
       "Name: Sentiment, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sentiment.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Username</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Overal Sentiment</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>6130</td>\n",
       "      <td>ZUL_Hasan</td>\n",
       "      <td>ISIS</td>\n",
       "      <td>TIPS jadi saksi nikah : Jangan baper .. Sesama...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>remarks: the ISIS in this context does not ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6534</th>\n",
       "      <td>6534</td>\n",
       "      <td>tifsembiring</td>\n",
       "      <td>ISIS</td>\n",
       "      <td>ISIS ...? ada yg bilang \"Istri Sholihah Idaman...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>remarks: ISIS here does not refer to the Islam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>6538</td>\n",
       "      <td>tifsembiring</td>\n",
       "      <td>HTI</td>\n",
       "      <td>@rayestu kmbalikan pd hti nurani mas, kita kom...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>remarks: hti nurani = hati nurani, does not re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      Username Keyword  \\\n",
       "6130        6130     ZUL_Hasan    ISIS   \n",
       "6534        6534  tifsembiring    ISIS   \n",
       "6538        6538  tifsembiring     HTI   \n",
       "\n",
       "                                                  Tweet Sentiment  \\\n",
       "6130  TIPS jadi saksi nikah : Jangan baper .. Sesama...       NaN   \n",
       "6534  ISIS ...? ada yg bilang \"Istri Sholihah Idaman...       NaN   \n",
       "6538  @rayestu kmbalikan pd hti nurani mas, kita kom...       NaN   \n",
       "\n",
       "     Overal Sentiment                                         Unnamed: 5  \n",
       "6130              NaN  remarks: the ISIS in this context does not ref...  \n",
       "6534              NaN  remarks: ISIS here does not refer to the Islam...  \n",
       "6538              NaN  remarks: hti nurani = hati nurani, does not re...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[pd.isnull(data[['Sentiment']]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv('data/Indonesian/indo_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = data_reader(config)\n",
    "dr.load_data(config.train_path)\n",
    "dr_valid = data_reader(config, False)\n",
    "dr_valid.load_data(config.valid_path)\n",
    "dr_test = data_reader(config, False)\n",
    "dr_test.load_data(config.test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = dr.generate_sample(dr.data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = ['ss', 'ff','df','gf']\n",
    "word_freq_pair = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {2: 805, 0: 2164, 1: 633})\n"
     ]
    }
   ],
   "source": [
    "data_batch = dh.to_batches(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset number: 606\n",
      "Target error meal\n",
      "Local Embeddings Saved!\n"
     ]
    }
   ],
   "source": [
    "data2 = dh.read(TEST_DATA_PATH, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = reader.generate_sample(train_batch)\n",
    "sent_vecs, mask_vecs, label_list, sent_lens = elmo_transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_vecs, mask_vecs, label_list, sent_lens = elmo_transform([test_batch[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write to pkl\n",
    "with open(DATA_FILE, \"wb\") as f:\n",
    "    pickle.dump([train_batch, test_batch],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(DIC_FILE, 'wb') as f:\n",
    "    pickle.dump(reader.id2word, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411 unk out of 5138 vocab\n"
     ]
    }
   ],
   "source": [
    "reader.gen_vectors_glove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardsun/anaconda3/envs/allennlp/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "from model_att import *\n",
    "model = attTSA(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:To Head:be Children: []\n",
      "Text:be Head:was Children: [To, fair]\n",
      "Text:completely Head:fair Children: []\n",
      "Text:fair Head:be Children: [completely]\n",
      "Text:, Head:was Children: []\n",
      "Text:the Head:factor Children: []\n",
      "Text:only Head:factor Children: []\n",
      "Text:redeeming Head:factor Children: []\n",
      "Text:factor Head:was Children: [the, only, redeeming]\n",
      "Text:was Head:was Children: [be, ,, factor, food, ,, but, make, .]\n",
      "Text:the Head:food Children: []\n",
      "Text:food Head:was Children: [the, ,, was]\n",
      "Text:, Head:food Children: []\n",
      "Text:which Head:was Children: []\n",
      "Text:was Head:food Children: [which, above]\n",
      "Text:above Head:was Children: [average]\n",
      "Text:average Head:above Children: []\n",
      "Text:, Head:was Children: []\n",
      "Text:but Head:was Children: []\n",
      "Text:could Head:make Children: []\n",
      "Text:n't Head:make Children: []\n",
      "Text:make Head:was Children: [could, n't, up, for]\n",
      "Text:up Head:make Children: []\n",
      "Text:for Head:make Children: [deficiencies]\n",
      "Text:all Head:deficiencies Children: []\n",
      "Text:the Head:deficiencies Children: []\n",
      "Text:other Head:deficiencies Children: []\n",
      "Text:deficiencies Head:for Children: [all, the, other, of]\n",
      "Text:of Head:deficiencies Children: [Teodora]\n",
      "Text:Teodora Head:of Children: []\n",
      "Text:. Head:was Children: []\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"To be completely fair, the only redeeming factor was the food, which was above average, but couldn't make up for all the other deficiencies of Teodora.\")\n",
    "target = 'food'\n",
    "for token in doc:\n",
    "#     if 'food' in token.head.text:\n",
    "#         print(token)\n",
    "#     children = [t.text for t in token.children]    \n",
    "#     if 'food' in children:\n",
    "#         print(token)\n",
    "    print('Text:'+ token.text, 'Head:'+token.head.text, 'Children:',\n",
    "           [child for child in token.children])\n",
    "#     if token.text == 'food':\n",
    "#         a = token\n",
    "#     if token.text == 'deficiencies':\n",
    "#         b= token\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be completely fair, the only redeeming factor was the food, which was above average, but couldn't make up for all the other deficiencies of Teodora.\n",
      "*******\n"
     ]
    }
   ],
   "source": [
    "for item in doc.sents:\n",
    "    print(item)\n",
    "    print('*******')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:the Head:screen Children: []\n",
      "Text:screen Head:is Children: [the]\n",
      "Text:is Head:is Children: [screen, good, but, sucks]\n",
      "Text:good Head:is Children: []\n",
      "Text:but Head:is Children: []\n",
      "Text:the Head:battery Children: []\n",
      "Text:battery Head:sucks Children: [the]\n",
      "Text:sucks Head:is Children: [battery]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'the screen is good but the battery sucks')\n",
    "for token in doc:\n",
    "#     if 'food' in token.head.text:\n",
    "#         print(token)\n",
    "#     children = [t.text for t in token.children]    \n",
    "#     if 'food' in children:\n",
    "#         print(token)\n",
    "    print('Text:'+ token.text, 'Head:'+token.head.text, 'Children:',\n",
    "           [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1450\" height=\"399.5\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">screen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">good</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">but</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">battery</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">sucks</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,266.5 L1283.0,254.5 1267.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='dep', jupyter=True)\n",
    "# trees = doc.print_tree()\n",
    "# trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Layer import SimpleCat\n",
    "from data_reader_general import dataHelper, data_generator\n",
    "#from model_glove import *\n",
    "from model_crf import *\n",
    "from config import config\n",
    "cat_layer = SimpleCat(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cat_layer.load_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent = 'To heal the hearts of believers and to enrage kuffar, \\\n",
    "munafikeen and murtadeen, we present the last video memoir of Shaheed Eisa Fazili. May Allah accept him into highest Jannah'\n",
    "targets = ['Eisa Fazili', 'kuffar', 'munafikeen', 'murtadeen', 'Allah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = \"But the staff was so good to us\"\n",
    "targets = ['staff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_list = []\n",
    "opinion_list = []\n",
    "SentInst = namedtuple(\"SentenceInstance\", \"id text text_ids text_inds opinions\")\n",
    "OpinionInst = namedtuple(\"OpinionInstance\", \"target_text polarity class_ind target_mask target_ids\")\n",
    "for target in targets:\n",
    "    opinion_inst = OpinionInst(target, 'negative', None, None, None)\n",
    "    opinion_list.append(opinion_inst)\n",
    "sent_Inst = SentInst(1, sent, None, None, opinion_list)\n",
    "sentence_list.append(sent_Inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dh = dataHelper(config)\n",
    "data, words = dh.process_raw_data(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {2: 5})\n"
     ]
    }
   ],
   "source": [
    "data_batch = dh.to_batches(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dg = data_generator(config, data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_vecs, mask_vecs, label_list, sent_lens = dg.elmo_transform(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = AspectSent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardsun/anaconda3/envs/allennlp/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/richardsun/anaconda3/envs/allennlp/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/richardsun/anaconda3/envs/allennlp/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('data/models/model.pt')\n",
    "sent_vecs = cat_layer(sent_vecs, mask_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_label, best_seq = model.predict(sent_vecs, mask_vecs, sent_lens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores, s_probs, best_seqs = model.compute_predict_scores(sent_vecs, mask_vecs, sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6032, -4.7932,  0.9438],\n",
       "        [ 2.6839, -5.2023,  1.0347],\n",
       "        [ 2.7342, -5.2895,  1.0273],\n",
       "        [ 2.7248, -5.2792,  1.0532],\n",
       "        [ 2.7875, -5.3021,  1.0744]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8397,  0.0005,  0.1598],\n",
       "        [ 0.8385,  0.0003,  0.1612],\n",
       "        [ 0.8462,  0.0003,  0.1535],\n",
       "        [ 0.8415,  0.0003,  0.1582],\n",
       "        [ 0.8470,  0.0003,  0.1527]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.softmax(scores, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_reader import data_reader\n",
    "dr = data_reader(config)\n",
    "dr.load_data(config.train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3001"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_list, mask_list, label_list, _ = zip(*dr.data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(label_list, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1816,  531,  654])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [[0,1,1,0],[0,1,0], [0,0,0,1,1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.zeros(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    temp = a[i]\n",
    "    b[i, :len(temp)] = torch.FloatTensor(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=torch.LongTensor([2,5,7,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_lens, perm_idx = a.sort(0, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[perm_idx[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7,  5,  4,  3,  2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from model_att_glove import *\n",
    "from data_reader_general import *\n",
    "from config import config\n",
    "import pickle\n",
    "from Layer import GloveMaskCat\n",
    "import numpy as np\n",
    "import codecs\n",
    "import copy\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dr = data_reader(config)\n",
    "train_data = dr.load_data(config.data_path+'Restaurants_Train_v2.xml.pkl')\n",
    "test_data = dr.load_data(config.data_path+'Restaurants_Test_Gold.xml.pkl')\n",
    "valid_data = dr.load_data(config.data_path+'valid_restaurant.pkl')\n",
    "dg_train = data_generator(config, train_data)\n",
    "dg_valid = data_generator(config, valid_data, False)\n",
    "dg_test =data_generator(config, test_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from data/2014/vocab/local_emb.pkl with shape (4334, 300)\n"
     ]
    }
   ],
   "source": [
    "cat_layer = GloveMaskCat(config)\n",
    "cat_layer.load_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_vecs, mask_vecs, label_list, sent_lens, tokens = next(dg_valid.get_ids_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_vecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   52,  2175,    11,  2176,   220,   102,    10,     3,   134,\n",
       "          983,  2177,     3,   451,  2178,     1,  2179,    11,   152,\n",
       "          834,   233,   218,    44,   260,    32,  1482,    37,     4,\n",
       "          511,    32,  2180,  2181,    38,     6,   116,  1184,    13,\n",
       "            1,   141,   107,     4,   984,     2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_vecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an',\n",
       " 'oasis',\n",
       " 'of',\n",
       " 'refinement',\n",
       " ':',\n",
       " ' ',\n",
       " 'food',\n",
       " ',',\n",
       " 'though',\n",
       " 'somewhat',\n",
       " 'uneven',\n",
       " ',',\n",
       " 'often',\n",
       " 'reaches',\n",
       " 'the',\n",
       " 'pinnacles',\n",
       " 'of',\n",
       " 'new',\n",
       " 'american',\n",
       " 'fine',\n",
       " 'cuisine',\n",
       " '  ',\n",
       " 'chef',\n",
       " \"'s\",\n",
       " 'passion',\n",
       " '(',\n",
       " 'and',\n",
       " 'kitchen',\n",
       " \"'s\",\n",
       " 'precise',\n",
       " 'execution',\n",
       " ')',\n",
       " 'is',\n",
       " 'most',\n",
       " 'evident',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fish',\n",
       " 'dishes',\n",
       " 'and',\n",
       " 'soups',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_attention(dr_test, model):\n",
    "    print(\"Evaluting\")\n",
    "    dr_test.reset_samples()\n",
    "    model.eval()\n",
    "    all_counter = 0\n",
    "    correct_count = 0\n",
    "    while dr_test.index < dr_test.data_len:\n",
    "        sent, mask, label, sent_len, tokens = next(dr_test.get_ids_samples())\n",
    "        sent, target = cat_layer(sent, mask)\n",
    "        if config.if_gpu: \n",
    "            sent, target = sent.cuda(), target.cuda()\n",
    "            label, sent_len = label.cuda(), sent_len.cuda()\n",
    "        pred_label, attentions  = model.predict(sent, target, sent_len) \n",
    "        print(tokens[:3])\n",
    "        print(mask[:3])\n",
    "        print(attentions[:3])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluting\n",
      "[['an', 'oasis', 'of', 'refinement', ':', ' ', 'food', ',', 'though', 'somewhat', 'uneven', ',', 'often', 'reaches', 'the', 'pinnacles', 'of', 'new', 'american', 'fine', 'cuisine', '  ', 'chef', \"'s\", 'passion', '(', 'and', 'kitchen', \"'s\", 'precise', 'execution', ')', 'is', 'most', 'evident', 'in', 'the', 'fish', 'dishes', 'and', 'soups', '.'], ['the', 'food', 'can', 'get', 'pricey', 'but', 'the', 'prixe', 'fixe', 'tasting', 'menu', 'is', 'the', 'greatest', 'food', 'for', 'a', 'good', 'price', 'and', 'they', 'cater', 'the', 'food', 'to', 'any', 'food', 'allergies', 'or', 'food', 'you', 'do', \"n't\", 'like', '.'], ['the', 'red', 'curry', 'is', 'weak', 'and', 'tasteless', ',', 'the', 'pad', 'thai', 'is', 'stuck', 'together', 'and', 'lumpy', ',', 'the', 'rice', 'is', 'often', 'overcooked', ',', 'and', 'the', 'seafood', 'is', 'pretty', 'sketchy', '.']]\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0],\n",
      "        [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor(1.00000e-02 *\n",
      "       [[[ 0.4153,  0.4311,  0.4129,  0.4147,  0.4132,  0.6607,  3.0489,\n",
      "           3.0490,  3.0490,  3.0490,  3.0490,  3.0490,  3.0490,  3.0490,\n",
      "           3.0490,  3.0490,  3.0489,  2.6214,  0.6024,  0.4271,  1.8440,\n",
      "           0.5916,  2.9807,  2.0470,  2.5822,  1.2471,  3.0465,  3.0490,\n",
      "           3.0490,  3.0490,  3.0490,  3.0490,  3.0490,  3.0490,  3.0490,\n",
      "           3.0490,  3.0490,  3.0490,  3.0490,  3.0490,  3.0490,  3.0367]],\n",
      "\n",
      "        [[ 0.5859,  0.6752,  0.5979,  1.3908,  4.3227,  4.3293,  4.3293,\n",
      "           4.3293,  4.3294,  4.3294,  4.3294,  4.3294,  4.3292,  4.3294,\n",
      "           4.3294,  4.3294,  4.3294,  4.3294,  4.3294,  4.3294,  4.3292,\n",
      "           4.2334,  0.5992,  0.7310,  0.5859,  0.5859,  0.5860,  0.5859,\n",
      "           0.5859,  0.5859,  0.5859,  0.5859,  0.5859,  0.5859,  0.5859,\n",
      "           1.5927,  1.5927,  1.5927,  1.5927,  1.5927,  1.5927,  1.5927]],\n",
      "\n",
      "        [[ 0.8920,  2.9054,  4.1142,  4.1341,  4.1525,  4.1484,  4.1332,\n",
      "           2.4000,  0.5727,  0.5698,  0.6120,  0.5734,  0.6592,  1.5546,\n",
      "           1.6337,  1.3939,  1.6087,  0.6152,  2.1349,  2.2245,  3.6625,\n",
      "           4.1788,  4.1770,  4.1785,  3.6205,  4.1797,  4.0064,  4.1742,\n",
      "           4.1774,  4.1543,  1.5382,  1.5382,  1.5382,  1.5382,  1.5382,\n",
      "           1.5382,  1.5382,  1.5382,  1.5382,  1.5382,  1.5382,  1.5382]]])\n"
     ]
    }
   ],
   "source": [
    "model_file = config.model_path+'model.pt'\n",
    "if os.path.exists(model_file):\n",
    "    model = torch.load(model_file)\n",
    "    visualize_attention(dg_valid, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
